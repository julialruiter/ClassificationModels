{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87be1d91",
   "metadata": {},
   "source": [
    "### Image Classification - Pokemon Edition\n",
    "To the human pokemon player, it's usually easy to guess what a pokemon's (primary) typing is just by looking at it -- anything that has wings is generally flying type; anything blue or a fish is usually water; scary-looking pokemon tend to be dark or poinson type (or both); bugs are bugs; if you obtained it from a fossil then it's rock; if it has a plant in its name--it's a grass type; and if it's yellow it's ~~pikachu~~ an electric type.  However, many of these assumptions are based on a human's background knowledge of nature or vocabulary, and can usually guess the pokemon typing with high accuracy.  But what if we strip away the name puns?  And what if we give them to a computer that knows nothing about references to nature and mythology?  **I want to know if a computer can guess pokemon types from their images** \n",
    "\n",
    "#### Dataset:\n",
    "Google overrepresents pikachu when you search \"pokemon\", so to make a more fair dataset, I'm instead using sprites from this site: https://pokemondb.net/sprites\n",
    "\n",
    "I'm using Generation 8 Sprites (clearest and most detailed art) for Generation 1 (only has 15 pokemon types instead of the 18 in Generation 8).  If there are gender differences in the pokemon sprites, only the female version will be downloaded.\n",
    "\n",
    "#### Method:\n",
    "Using the methods from HW 5.1, I will classify pokemon.  However, Imagenet alone is not the right pretrained base model for this task--Imagenet is trained on photographs while the data here are clipart-style sprites.  This is why the imagenet model will be finetuned with a sample of the pokemon sprites.\n",
    "\n",
    "I will manually classify the types for Generation 1, sample a subportion, and use this to create a model; then remaining Generation 1 is the \"untrained\" data set that will be used to test the model.\n",
    "\n",
    "Note:  for dual-type pokemon, pokemon will be classified by their primary typing (first-listed).\n",
    "\n",
    "#### Hypothesis:\n",
    "I believe that the model will have a difficult time classifying water and normal type pokemon due to the wide varity of sprite shapes and colors in these categories--and because both of these categories are so large and varied, neither can be considered the \"default\" category.  \n",
    "\n",
    "While the flying type category is the most distinctive, for Generation 1 there are *no* pure-flying types, and furthermore all pokemon that are part flying have it as their second typing.  The good news is that this means there's an entire classification category that's been eliminated, but unfortunately it was the most visually distin tive category.  The distribution of winged pokemon to other types will likely decrease the accuracy of the model as overall pokemon form now contributes less.\n",
    "\n",
    "I do forsee that there is too much noise in the training set -- with only 151 pokemon split across 15 types, there's not much training data in any one classification category.  Despite this, I think the Generation 1 pokemon sprites are simple and consistent enough to yeild a reasonable accurate classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd730578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import socket\n",
    "#socket.setdefaulttimeout(10)\n",
    "from shutil import copyfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import classification_report   # pretty stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475aa5c",
   "metadata": {},
   "source": [
    "#### Step 1: Create 'train',  'test', and 'validation' subsets from the 14 (remaining) classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b00c3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 files belonging to 14 classes.\n",
      "Found 55 files belonging to 14 classes.\n",
      "Found 62 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "# helper function to split the images into train/test/validate sets\n",
    "def custom_split_train_test_val(directory, sample_size=0.75):    # function from manual\n",
    "    subsets = ['train', 'test', 'val']\n",
    "\n",
    "    upper_dir = os.path.dirname(os.path.dirname(directory))\n",
    "    for subset in subsets:\n",
    "        if not os.path.exists(os.path.join(upper_dir, subset)):\n",
    "            os.mkdir(os.path.join(upper_dir, subset))\n",
    "    for label in os.listdir(directory):\n",
    "        path = os.path.join(directory, label)\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "            \n",
    "        images = [image for image in sorted(os.listdir(path)) if image[-3:] in ['jpg', 'gif', 'epg', 'png']]\n",
    "        size_train = int((1 - sample_size) * len(images))\n",
    "        size_test = int((len(images) - size_train) / 2)   \n",
    "        \n",
    "        for subset in subsets:\n",
    "            assert not os.path.exists(os.path.join(upper_dir, subset, label)), \"Path already exists, delete it first\"\n",
    "            os.mkdir(os.path.join(upper_dir, subset, label))\n",
    "        for train_image in images[:size_train]:\n",
    "            copyfile(os.path.join(path, train_image), \n",
    "                    os.path.join(upper_dir, 'train', label, train_image))\n",
    "        for test_image in images[size_train:size_train + size_test]:\n",
    "            copyfile(os.path.join(path, test_image), \n",
    "                    os.path.join(upper_dir, 'test', label, test_image))\n",
    "        for val_image in images[size_train + size_test:]:\n",
    "            copyfile(os.path.join(path, val_image), \n",
    "                    os.path.join(upper_dir, 'val', label, val_image))\n",
    "\n",
    "IMAGE_DIR = 'pokemon/types/'     # directory where original classifications are stored\n",
    "custom_split_train_test_val(IMAGE_DIR, sample_size=0.75)  # with so few pokemon per category, sample as many per category as possible\n",
    "\n",
    "\n",
    "# custom split information\n",
    "IMAGE_SIZE = (128,128)   # this is shy I used the dataset I did:  consistent image size\n",
    "path = os.path.join('pokemon/')  # this is where the original images are stored\n",
    "\n",
    "train_ds = image_dataset_from_directory(    # used to fine-tune the existing Imagenet model\n",
    "    path + '/train/'  ,   \n",
    "    shuffle=True,\n",
    "    image_size= IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=64,  \n",
    "    )\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    path + '/test/' ,\n",
    "    shuffle=False,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    path + '/val/' ,\n",
    "    shuffle=False,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "\n",
    "# improve speed by precessing multiple baches at once with tensorflow AUTOTUNE (optional)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae610d15",
   "metadata": {},
   "source": [
    "#### Step 2:  Train the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e311529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "preprocessing (Lambda)       (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 57,147,268\n",
      "Trainable params: 33,559,556\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# steps from manual\n",
    "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False  # only get attributes rom resnet; to not add to training data\n",
    "\n",
    "\n",
    "# using resnet to make a model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Lambda(preprocess_input, name='preprocessing', input_shape=IMG_SHAPE))\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))  # 4 because there are 4 classes\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# compile the model\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         min_delta=0, patience=2, verbose=0, \n",
    "                          mode='min', baseline=None, \n",
    "                      restore_best_weights=True)]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732c0d4",
   "metadata": {},
   "source": [
    "#### Step 3:  Assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ff448b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024D534C2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 5s 619ms/step\n",
      "[[3 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [3 0 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 6 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_ds, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = np.argmax(np.concatenate([labels.numpy() for images, labels in test_ds.take(-1)]), axis=1)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))  # this is a lot easier to read than the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4e6e4",
   "metadata": {},
   "source": [
    "As you can see, the performance is absolutely **abysmal**.  No matter how many times I rerun the model, I only ever get images in 2 or 3 categories.\n",
    "\n",
    "I have a feeling that there are too many categories and not enough data in each category.  Let's take a look at what the pokemon type distribution actually is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1dd61141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>total_pokemon</th>\n",
       "      <th>in_training_set</th>\n",
       "      <th>in_test_set</th>\n",
       "      <th>in_validation_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bug</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dragon</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electric</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fighting</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fire</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ghost</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grass</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ground</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ice</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>poison</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>psychic</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rock</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>water</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  total_pokemon  in_training_set  in_test_set  in_validation_set\n",
       "0        bug             12                3            4                  5\n",
       "1     dragon              3                0            1                  2\n",
       "2   electric              9                2            3                  4\n",
       "3   fighting              8                2            3                  3\n",
       "4       fire             12                3            4                  5\n",
       "5      ghost              3                0            1                  2\n",
       "6      grass             12                3            4                  5\n",
       "7     ground              8                2            3                  3\n",
       "8        ice              2                0            1                  1\n",
       "9     normal             26                6           10                 10\n",
       "10    poison             15                3            6                  6\n",
       "11   psychic              8                2            3                  3\n",
       "12      rock              9                2            3                  4\n",
       "13     water             24                6            9                  9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lists with stats per category\n",
    "type_list = []\n",
    "pokemon_count = []\n",
    "train_count = []\n",
    "test_count = []\n",
    "val_count = []\n",
    "directory = \"pokemon/types/\"\n",
    "\n",
    "for poke_type in os.listdir(directory):\n",
    "    type_list.append(poke_type)    # add pokemon typing to list\n",
    "    \n",
    "    count = 0\n",
    "    type_dir = directory + str(poke_type) + '/'\n",
    "    for file in os.listdir(type_dir):\n",
    "        count += 1\n",
    "    pokemon_count.append(count)\n",
    "\n",
    "\n",
    "# now repeat processs on the split sets\n",
    "for poke_type in type_list:\n",
    "    train_counter = 0\n",
    "    train_dir = \"pokemon/train/\" + str(poke_type) + '/'\n",
    "    for file in os.listdir(train_dir):\n",
    "        train_counter += 1  \n",
    "    train_count.append(train_counter)\n",
    "    \n",
    "    test_counter = 0\n",
    "    test_dir = \"pokemon/test/\" + str(poke_type) + '/'\n",
    "    for file in os.listdir(test_dir):\n",
    "        test_counter += 1  \n",
    "    test_count.append(test_counter)\n",
    "    \n",
    "    val_counter = 0\n",
    "    val_dir = \"pokemon/val/\" + str(poke_type) + '/'\n",
    "    for file in os.listdir(val_dir):\n",
    "        val_counter += 1\n",
    "    val_count.append(val_counter)\n",
    "\n",
    "\n",
    "# create dataframe from the lists\n",
    "poke_stats_df = pd.DataFrame({\n",
    "    'type': type_list,\n",
    "    'total_pokemon': pokemon_count,\n",
    "    'in_training_set': train_count,\n",
    "    'in_test_set': test_count,\n",
    "    'in_validation_set': val_count\n",
    "})\n",
    "poke_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638829ff",
   "metadata": {},
   "source": [
    "Now the problem is obvious: most pokemon types have too few images, and therefore have too few in the training set.  With such a small training set, any major differences in images within that classification will make it difficult to train and validate a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c972f",
   "metadata": {},
   "source": [
    "## Step 4:  Define a more reasonable research question\n",
    "To give the model a better chance at discerning type differences, we will:\n",
    "1. decrease the number of categories to choose from\n",
    "2. only choose categories with a significant number of pokemon\n",
    "\n",
    "#### New question:\n",
    "Can a computer distinguish between fire, poison, and normal type pokemon? (3 of the top categories)\n",
    "\n",
    "#### Preprocessing:\n",
    "These 3 types have been copied into a new directory called 'reduced_types'\n",
    "\n",
    "#### Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f98a5d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 files belonging to 3 classes.\n",
      "Found 20 files belonging to 3 classes.\n",
      "Found 21 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# New split on the reduced dataset:\n",
    "IMAGE_DIR = 'pokemon/reduced_types/'     # directory where original classifications are stored\n",
    "custom_split_train_test_val(IMAGE_DIR, sample_size=0.75)  # with so few pokemon per category, use half of each category to sample\n",
    "\n",
    "IMAGE_SIZE = (128,128)   # this is shy I used the dataset I did:  consistent image size\n",
    "path = os.path.join('pokemon/')  # this is where the original images are stored\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    path + '/train/'  ,   \n",
    "    shuffle=True,\n",
    "    image_size= IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=64,  \n",
    "    )\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    path + '/test/' ,\n",
    "    shuffle=False,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    path + '/val/' ,\n",
    "    shuffle=False,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "\n",
    "# improve speed by precessing multiple baches at once with tensorflow AUTOTUNE (optional)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25245b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "preprocessing (Lambda)       (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 57,147,268\n",
      "Trainable params: 33,559,556\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CREATE A NEW MODEL: \n",
    "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False  # only get attributes rom resnet; to not add to training data\n",
    "\n",
    "# using resnet to make a model\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Lambda(preprocess_input, name='preprocessing', input_shape=IMG_SHAPE))\n",
    "model2.add(base_model)\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dropout(0.3))\n",
    "model2.add(tf.keras.layers.Dense(4, activation='softmax'))  # 4 because there are 4 classes\n",
    "model2.summary()\n",
    "\n",
    "# compile the model\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         min_delta=0, patience=2, verbose=0, \n",
    "                          mode='min', baseline=None, \n",
    "                      restore_best_weights=True)]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b24fce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 284ms/step\n",
      "[[ 3  0  1]\n",
      " [10  0  0]\n",
      " [ 5  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# ASSESS THE MODEL\n",
    "predictions2 = model2.predict(test_ds, verbose=1)\n",
    "y_pred = np.argmax(predictions2, axis=1)\n",
    "y_true = np.argmax(np.concatenate([labels.numpy() for images, labels in test_ds.take(-1)]), axis=1)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49990dc",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "Even when reducing the sample data to 3 clearly defined categories, it seems that the model classification precision is quite low.\n",
    "\n",
    "This means that a pokemon's type recognizability doesn't come from its appearance alone.\n",
    "\n",
    "The final dataset used for this 3-type classification task was 53 pokemon out of the available 151.  With 898 pokemon currently in the Generation 8 Pokedex, there is the potential for a lot more sample data.  If I were to continue this project, I would elicit the help of a couple friends to classify the remaining 700-ish pokemon, and retry the 14-type, 3-type, and full 18-type model creations.  I anticipate that vastly increasing sample size will yeild better results as it will decrease the overall noise and outlier influence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
